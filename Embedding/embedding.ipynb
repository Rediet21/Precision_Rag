{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ddcbec-fca1-4739-aa7d-27c05ef623e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "#from ray.data import ActorPoolStrategy\n",
    "\n",
    "class EmbedChunks:\n",
    "    def __init__(self):\n",
    "       \n",
    "        self.embedding_model = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "      \n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        embeddings = self.embedding_model.embed_documents(batch[\"question\"])\n",
    "       \n",
    "        return pd.DataFrame({\"question\": batch[\"question\"], \"solution\": batch[\"solution\"], \"embeddings\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7720bdf-46c0-48f0-99e9-b5df857dc806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.conda\\envs\\week6_env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question      An image is represented by an m x n integer gr...\n",
      "solution      class Solution {\\npublic:\\n    void bfs(int pr...\n",
      "embeddings    [0.019774852960477488, 0.013059384313380287, -...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from datasets import load_dataset\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "data_path = \"../dataset/data.jsonl\"\n",
    "\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "# embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\",openai_api_key=openai_api_key)\n",
    "# texts = df['question']\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# dataset = load_dataset(\n",
    "#     data_path,\n",
    "#     split=\"test\"\n",
    "# )\n",
    "# Instantiate the EmbedChunks class\n",
    "embedder = EmbedChunks()\n",
    "\n",
    "# Apply the __call__ method to each example in the dataset\n",
    "# embeded_chunk = dataset.map(embedder, batched=True)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Split the DataFrame into batches\n",
    "batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "# Apply the function to each batch\n",
    "processed_batches = [embedder.process_batch(batch) for batch in batches]\n",
    "\n",
    "# Concatenate the processed batches back into a single DataFrame\n",
    "embeded_chunk = pd.concat(processed_batches, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Embed chunks\n",
    "# embeded_chunk = df.map_batches( \n",
    "#     EmbedChunks,\n",
    "#     batch_size=100, \n",
    "#     # num_gpus=1\n",
    "#     )\n",
    "# embeded_chunk = embed_model.embed_documents(texts)\n",
    "# len(embeded_chunk), len(embeded_chunk[0])\n",
    "#for i, embeded_chunk in enumerate(embeded_chunk):\n",
    "    #print(f\"Embedded representation for chunk {i+1}:\")\n",
    "print(embeded_chunk.iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9be769-1c5d-419a-bd2b-5022fab55d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "\n",
    "class StoreResults:\n",
    "    def __call__(self, batch):\n",
    "        # Establish a connection to the database using the DB_CONNECTION_STRING from the environment variables\n",
    "        with psycopg.connect(os.environ[\"DB_CONNECTION_STRING\"]) as conn:\n",
    "            # Register the vector type in the database (assuming it's a custom vector type)\n",
    "            register_vector(conn)\n",
    "            with conn.cursor() as cur:\n",
    "                # Iterate over each element in the batch and insert the data into the database\n",
    "                for question, solution, embeded_chunk in zip(batch[\"question\"], batch[\"solution\"], batch[\"embeded_chunk\"]):\n",
    "                    cur.execute(\"INSERT INTO document (question, solution, embeded_chunk) VALUES (%s, %s, %s)\",\n",
    "                                (question, solution, embeded_chunk,))\n",
    "        # Return an empty dictionary\n",
    "        return {}\n",
    "\n",
    "store_results = StoreResults()  # Instantiate the StoreResults object\n",
    "\n",
    "# Iterate over the elements of embeded_chunk using tqdm\n",
    "for _, row in tqdm(embeded_chunk.iterrows(), total=len(embeded_chunk), desc=\"Processing\"): \n",
    "    StoreResults()(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca49cf9-3c22-4315-b1e9-1e3ee0231473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index data\n",
    "embedded_chunks.map_batches(\n",
    "    StoreResults,\n",
    "    batch_size=128,\n",
    "    num_cpus=1,\n",
    "    compute=ActorPoolStrategy(size=28),\n",
    ").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
